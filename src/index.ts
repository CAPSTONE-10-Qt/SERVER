import express, { NextFunction, Request, Response } from 'express';
import Configuration, { OpenAI } from 'openai';
import OpenAIApi from 'openai';
import config from './config';
import router from './router'
import * as dotenv from 'dotenv'
import errorHandler from './middleware/error/errorHandler';
import cors from 'cors';

dotenv.config()
const axios = require('axios')
const app = express(); // express ê°ì²´ ë°›ì•„ì˜´ 

const allowedOrigins = [
  'http://localhost:8000',
  'http://localhost:3000',
  config.ec2URL,
];
const corsOptions = {
  origin: allowedOrigins,
  credentials: true,
};

app.use(cors(corsOptions));
app.use((req, res, next) => {
  const origin: string = req.headers.origin!;
  if (allowedOrigins.includes(origin)) {
    res.setHeader('Access-Control-Allow-Origin', origin);
  }
  res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, PATCH');
  res.header(
    'Access-Control-Allow-Headers',
    'X-Requested-With, content-type, x-access-token',
  );
  next();
});

app.use(express.json());
app.use(express.urlencoded({ extended: true }));
app.use('/', router);

const openai = new OpenAI({
  organization: "org-5IqT7dxuJeAfuyJEJJhg8VXq",
  apiKey: process.env.OPEN_API_KEY
});

export const Answer = async (questionText: string, text: string) => {
  try {
    const completion = await openai.completions.create({
      model: "gpt-3.5-turbo-instruct",
      temperature: 0,
      user: 'IT company interviewer',
      prompt: "ë„ˆê°€ í•œ ë©´ì ‘ ì§ˆë¬¸ì€ ì´ê±°ê³  "+questionText+", ë©´ì ‘ìžì˜ ë‹µë³€ì€ ë‹¤ìŒê³¼ê°™ì•„."+text+ "ë©´ì ‘ìžì— ëŒ€í•œ í”¼ë“œë°±ì„ ëŒ€ë‹µì˜ ì¢‹ì€ ì , í‹€ë¦° ë‚´ìš©ê³¼ ì²¨ì‚­, ì•„ì‰¬ì› ë˜ ë¶€ë¶„ ë“±ì„ ê¼­ í¬í•¨í•´ì„œ ê³µë°±í¬í•¨ 400ìžë¡œ ìž‘ì„±í•´ì¤˜.",
      max_tokens: 400
    });
    const result = completion.choices[0].text;
    return result;
  } catch(error) {
    throw error;
  }
};

export const Score = async (questionText: string, text: string) => {
  try {
    const completion = await openai.completions.create({
      model: "gpt-3.5-turbo-instruct",
      temperature: 0,
      user: 'IT company interviewer',
      prompt: questionText+"ì´ê²Œ ë©´ì ‘ ì§ˆë¬¸ì´ê³ ,"+text+"ì´ê²Œ ë‹µë³€ ë‚´ìš©ì´ì•¼. ì±„ì í‘œì—ëŠ” 0ì , 0.5ì , 1ì  ë§Œ ìžˆì–´. ëª‡ì  ì¤„ê±°ì•¼?",
      max_tokens: 3
    });
    const result = completion.choices[0].text;
    return result;
  } catch(error) {
    throw error;
  }
};

app.post('/api/chat', async (req, res) => {
  try {
  const { message } = req.body
  const completion = await openai.completions.create({
      model: "gpt-3.5-turbo-instruct",
      prompt: message,
      max_tokens:20
    });
  res.json({ response: completion.choices[0].text })
} catch (error) {
res.json({error})       
}
})

//Error Handler
interface ErrorType {
  message: string;
  status: number;
}

app.use(function (
  err: ErrorType,
  req: Request,
  res: Response,
  next: NextFunction,
) {
  res.locals.message = err.message;
  res.locals.error = req.app.get('env') === 'production' ? err : {};

  // render the error page
  res.status(err.status || 500);
  res.json({ error: err })
});

app.listen(config.port, () => {
  console.log(`
        #############################################
            ðŸ›¡ï¸ Server listening on port: ${config.port} ðŸ›¡ï¸
        #############################################
    `);
})
.on('error', (err) => {
  console.error(err);
  process.exit(1);
});

export default app;